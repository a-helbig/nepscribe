# regex to use in rstudio to remove all starting and ending quot marks and commas: ^"|"$|,$

# script function --------------------------------------------------------

# function that generates the scripts
gen_script <- function(datapath_conv, suf_version, suf_version_short, dataformat, format = "personyear", subformat, datalist, prio, english, set_missings, parallel, further_training, education, children){
  prio_var <- as.numeric(str_extract_all(prio, "\\d{2}"))
  sc <- toupper(identify_sc(datapath_conv))
  if(dataformat== "R" & subformat == "Harmonized Spell Format (Recommended)"){
    scripts <- c(
      paste0(
        "# Base script to transform NEPS ", sc, " SUF data into a person-year format"),
      "# It uses the harmonized spells (subspell==0) from the biography data as a base for this transformation process.",
      "# If you want acess to within spell variation across waves, spell related longitudinal information should be joined via 'ID_t', 'wave' and 'splink' after step 7, when the person-year structure has been generated and after dropping harmonized episodes in the spellfiles via 'keep if spstat < 30'. When you use the 'Additional variables' function in the app, this process is used. It ensures that timevariant spell information is not being lost. However it requires a handling of various missing value codes due to filtering or data issues. Examples are provided when using the 'Additional variables' function",
      "",
      "# !!!ATTENTION!!!" ,
      "# This is a basic data preparation script which serves the purpose of demonstrating how one might generate a dataset in person-year-format by taking the harmonized spells from biography as a baseline and merge infos from other datasets. Edits to the script that fit to you research project are possibly necessary and recommended.",
      "",
      "# Script uses mostly dplyr due to its simplicity and sometimes base R for performance reasons. ",
      "",
      "# After the expanding to a monthly structure, which creates a huge dataframe, the script uses occasionally the lazy_dt function from dtplyr package to get the fastest solution outside of data.table package",
      "",
      "# Code might need a new intendation and formating: Try Strg+A and then Strg+Shift+A in RStudio",
      "",
      "# Approach:",
      "",
      "# 1. Step: Load Biography dataset as a base for the person-year-dataset and generate start-, enddate and duration variables",
      "",
      "# 2. Step: Load Employment dataset and join it to biograhpy in order to get access to working hours variable. This variable will be used in step 6 for priorisation of episode types",
      "",
      "# 3. Step: Load Voctrain dataset and join it to biograhpy in order to get access to type of vocational training variable. This variable will also be used in the priorisation process",
      "",
      "# 4. Step: Load Cohortprofile dataset and join it to biograhpy in order to get access to the interview dates. These are necessary for converting data into a person-year format, as this format focuses on respondents' information at each interview date.",
      "",
      "# 5. Step: Expand the data to a monthly format by multiplying each row of each respondent with the spell length in month (dur variable). This serves as the basis for the prioritization process in the next step.",
      "",
      "# 6. Step: Priorisation process. Here, we sort the months of each respondent by determined spell order, main/side episode (descending), working hours (descending), employment duration (descending) and splink. You may edit this according to your research question(s).",
      "",
      "# 7. Step: Reduce rows in dataset to interview date months by loading cohort profile, generating month variable and then left joining biography data by ID_t and month. This will lead to a dataset with 1 row per wave of each respondent (what we call: 'person-year-dataset')",
      "",
      "# Additional data preparation steps may vary based on the settings configured in the Transform Data tab of the SUF-Explorer",
      "",
      "# Please carefully check each line and edit the script according to the needs of your research project",
      "",
      "rm(list = ls())",
      "",
      "# packages ----------------------------------------------------------------",
      "list.of.packages <- c('dtplyr','haven','dplyr','tidyr','janitor','readstata13','stringr', 'remotes')",
      "new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])] # check if required packages are in installed packages on this machine",
      "if(length(new.packages)) install.packages (new.packages) # if new.packages contains sth and thus length is > 0, install those new packages",
      "",
      "# install nepstools if not installed ",
      "if(!'nepstools' %in% installed.packages()) {",
      " remotes::install_github('a-helbig/nepstools')",
      "}",
      "",
      "# add nepstools to list.of.packages",
      "list.of.packages <- append(list.of.packages, 'nepstools')",
      "invisible(lapply(list.of.packages, library, character.only = TRUE))",
      "",
      paste0("datapath = ","'",datapath_conv,"/","'"),
      paste0("suf_version = ", "'", suf_version,"'"),
      paste0("suf_version_short = ", "'", suf_version_short,"'"),
      paste0("english = ", english),
      paste0("sc = ", "'",sc,"'"),
      "",
      "# 1. base: biography file ---------------------------------------------------------------------",
      "bio <- read_neps(paste0(datapath, '/', sc, '_Biography_D_', suf_version,'.dta'), english = english) |> ",
      "  replace_values_with_na() # We need to set missings in the biography data to get only positive values in the dur variable generated in the next step. We need this 'dur' variable later for expanding the dataset to a monthly structure", #- in contrast we wont set missings in employment and voctrain data in order to get the same priorisation as in stata and to preserve the possibility in stata to have extended missings (these extended missings otherwise would have an impact on the ordering in stata prep compared to Rs prep)
      "",
      "#gen episode dates vars: transform date vars to one variable in the format: 'months since 1960' and get rid of episodes with missing date values. ",
      "bio <- bio |> ",
      "  mutate(start=((starty-1960)*12)+startm-1,",
      "         end=((endy-1960)*12)+endm-1,",
      "         dur = end-start+1)  |> ",
      "  filter(!is.na(start) & !is.na(end)) |> ",
      "  select(-startm,-starty,-endm,-endy)",
      "",
      "# Assign varlabels to variables",
      if(english)"attr(bio$start, 'label') <- 'Start date'",
      if(english)"attr(bio$end, 'label') <- 'End date'",
      if(english)"attr(bio$dur, 'label') <- 'Duration'",
      if(!english)"attr(bio$start, 'label') <- 'Startdatum'",
      if(!english)"attr(bio$end, 'label') <- 'Enddatum'",
      if(!english)"attr(bio$dur, 'label') <- 'Dauer'",
      "",
      "# 2. employment info for Priorisation ---------------------------------------------------------------------",
      "# join employment data, recode working hours and reduce to harmonized episodes (subspell==0)",
      if(sc == "SC6") "cols <- c('ID_t', 'splink', 'spell','subspell', 'ts23223_g1')"
      else "cols <- c('ID_t', 'splink', 'spell','subspell', 'ts23223')",
      "emp <- read_neps(paste0(datapath, '/', sc, '_spEmp_D_', suf_version,'.dta'), col_select = cols, english = english",") |> ",
      "  filter(subspell == 0) ",
      "",
      if (sc == "SC6")  "emp <- emp |> ",
      if (sc == "SC6")    "rename(ts23223 = ts23223_g1)",
      "",
      "emp$ts23223[emp$ts23223 == -21] <- NA # work time not specified",
      "emp$ts23223[emp$ts23223 == -20] <- 90 # more than 90 hours per week",
      "",
      "bio <- left_join(bio, emp, by=c('ID_t', 'splink'))",
      "rm(emp)",
      "",
      "# 3. Voc Train Prep for Priorisation -----------------------------------------",
      if(sc == "SC6") "# join voctrain data, recode type of voc. training (different variable in Wave 1: ts15201_v1), and reduce to harmonized episodes (subspell==0)",
      if(sc == "SC6")"suppressWarnings({ # warnings are suppressed here because case_match throws a warning due to conflicting variable labels in ts15201 and ts15201_v1. This doesnt matter, because in the new variable 'vt_typ' the variable labels from ts15201 are being used and that is preferable in most cases. Change this if neccessary.",
      if(sc == "SC6")"voctrain <- read_neps(paste0(datapath, '/', sc, '_spVocTrain_D_', suf_version,'.dta'), col_select = c('ID_t', 'splink', 'subspell', 'ts15201_v1', 'ts15201'), english = english) |> ",
      if(sc == "SC6")"  mutate(ts15201_v1 = case_match(ts15201_v1, # here the codes from the old voctrain-type var from wave 1 (ts15201_v1) are aligned with the new voctrain-type var ts15201 from wave 2+",
      if(sc == "SC6")"  2 ~ 3, ",
      if(sc == "SC6")"  3 ~ 4, ",
      if(sc == "SC6")"  4 ~ 5, ",
      if(sc == "SC6")"  5 ~ 6, ",
      if(sc == "SC6")"  6 ~ 9, ",
      if(sc == "SC6")"  7 ~ 10, ",
      if(sc == "SC6")"  8 ~ 15, ",
      if(sc == "SC6")"  9 ~ 16, ",
      if(sc == "SC6")"  10 ~ 11, ",
      if(sc == "SC6")"  11 ~ 12, ",
      if(sc == "SC6")"  12 ~ 13, ",
      if(sc == "SC6")"  13 ~ 14, ",
      if(sc == "SC6")"  14 ~ 17,",
      if(sc == "SC6")"  .default = ts15201_v1),",
      if(sc == "SC6")"  # Replace vttyp with recoded ts15201_v1 where vttyp is -54 (wave 1)",
      if(sc == "SC6")"  vt_typ = ts15201,",
      if(sc == "SC6")"  vt_typ = if_else(vt_typ == -54, ts15201_v1, vt_typ)) |>",
      if(sc == "SC6")"  filter(subspell == 0) |> ",
      if(sc == "SC6")"  select(-ts15201,-ts15201_v1, -subspell)",
      if(sc == "SC6")"})",
      if(sc %in% c("SC3","SC4","SC5")) "voctrain <- read_neps(paste0(datapath, '/', sc, '_spVocTrain_D_', suf_version,'.dta'), english = english, col_select = c('ID_t', 'splink','subspell', 'ts15201')) |> ",
      if(sc %in% c("SC3","SC4","SC5"))"mutate(vt_typ = ts15201) |> ",
      if(sc %in% c("SC3","SC4","SC5"))"filter(subspell == 0) |> ",
      if(sc %in% c("SC3","SC4","SC5"))"select(-ts15201, -subspell)",
      "",
      "bio <- left_join(bio, voctrain, by=c('ID_t', 'splink'))",
      "rm(voctrain)",
      "",
      "# 4. merge interview dates ---------------------------------------------------",
      "cohort_profile <- read_neps(paste0(datapath, '/', sc,'_CohortProfile_D_', suf_version,'.dta'), english = english)",
      "",
      if(sc == "SC6")" cohort_profile <- cohort_profile |> select(ID_t, wave, tx8601y, tx8601m) |> rename(tx8600m = tx8601m, tx8600y = tx8601y) |> ",
      if(sc %in% c("SC4", "SC5")) "cohort_profile <- cohort_profile |>
        select(ID_t, wave, tx8600y, tx8600m) |> ",
      if(sc == "SC3") "cohort_profile <- cohort_profile |>
        select(ID_t, wave, tx8601y, tx8601m) |>
        rename(tx8600m = tx8601m, tx8600y = tx8601y) |> ",
      "  replace_values_with_na() |> ",
      "  mutate(intd=((tx8600y-1960)*12)+tx8600m-1) |> ",
      "  select(-tx8600y, -tx8600m)",
      "",
      "cohort_profile <- cohort_profile |> ",
      "  arrange(ID_t, wave) |> ",
      "  group_by(ID_t) |> ",
      "  mutate(firstwave= head(wave,1)) |> ",
      "  ungroup() |> ",
      "  mutate(wave = paste0('intd',wave)) |> ",
      "  pivot_wider(names_from = wave, values_from = intd)",
      "",
      "bio <- left_join(bio, cohort_profile, by = 'ID_t')",
      "",
      "# 5. expand to monthly structure -------------------------------------------",
      "",
      "# the expand function will generate one row for each month in the generated duration variable ('dur')",
      "bio <-  nepstools::expand(bio, dur)",
      "",
      "# create indicator 'month' ",
      "bio <- bio |>",
      "  lazy_dt() |> # use this function from dtplyr for faster processing",
      "  arrange(ID_t, splink) |>",
      "  group_by(ID_t, splink) |>",
      "  mutate(month = start + row_number() - 1) |>",
      "  ungroup() |>",
      "  as_tibble()",
      "",
      "# 6. priorisation process ----------------------------------------------------",
      "# recode licences courses and ihk courses to value 31 to place it behind xmodule episodes in the priorisation order because these types of episodes are typically rather side spells than main spells and thus considered of lesser importance in many research projects with regard to spell priorisation.",
      "",
      "bio <- bio |>",
      "  mutate(prio = sptype,",
      "  prio = if_else(vt_typ %in% c(13,14), 31, prio),",
      "  prio = case_when(",
      paste("  prio == ",prio_var[1]," ~ 1,"),
      paste("  prio == ",prio_var[2]," ~ 2,"),
      paste("  prio == ",prio_var[3]," ~ 3,"),
      paste("  prio == ",prio_var[4]," ~ 4,"),
      paste("  prio == ",prio_var[5]," ~ 5,"),
      paste("  prio == ",prio_var[6]," ~ 6,"),
      paste("  prio == ",prio_var[7]," ~ 7,"),
      paste("  prio == ",prio_var[8]," ~ 8,"),
      paste("  prio == ",prio_var[9]," ~ 9,"),
      paste("  prio == ",prio_var[10]," ~ 10,"),
      "  TRUE ~ NA_real_  # For values not specified, set to NA",
      "))",
      "",
      "# recode these 2 variables in order to use them  in the priorisation process (do it here due to speed issues later after the expanding)",
      "bio$spms[bio$spms == 2] <- 0",
      "bio$spms[is.na(bio$spms)] <- 0",
      "bio$worktime <- bio$ts23223",
      "bio$worktime[is.na(bio$ts23223)] <- 0",
      "",
      "# to prioritize multiple parallel employment spells, we consider multiple variables in the following order of relevance: prio, spms (main vs side episode), working hours, employment duration and splink. Edit if necessary",
      "",
      "# Sort the data frame in this order",
      "bio$worktime <- as.numeric(bio$worktime) # as.numeric for sorting ",
      "bio$spms <- as.numeric(bio$spms) # as.numeric for sorting ",
      "bio <- bio[order(bio$ID_t, bio$month, bio$prio, -bio$spms, -bio$worktime, -bio$dur, bio$splink),]",
      "",
      if(parallel) gen_parallel_spells_r(format="harmonized"),
      "# Priorisation: Remove duplicates, keeping only the first row for each group of combination of ID_t and month (base R here because its faster than dplyr solution with row_number())",
      "bio <- bio[!duplicated(bio[c('ID_t', 'month')]), ]",
      "",
      "# Drop unnecessary variables",
      "bio <- bio |> select(-wave, -spms, -prio, -ts23223, -vt_typ) # drop wave variable here in order to get the real wave variable from cohort profile in the next step",
      "",
      "# 7. create person year format -------------------------------------",
      "",
      "# load interview dates from cohortprofile and left_join it to the biography by ID_t and month. This will keep only rows (months) in the bio dataset that correspond to actual interview dates from cohort profile. Finally this leads to a format with 1 row per year of a person where information is centered around each interview date.",
      "cohort_profile <- read_neps(paste0(datapath, '/', sc, '_CohortProfile_D_', suf_version,'.dta'), english = english)",
      "",
      if(sc == "SC6")" cohort_profile <- cohort_profile |>
      select(ID_t, wave, tx8601y, tx8601m, tx80220) |>
      rename(tx8600m = tx8601m, tx8600y = tx8601y) |> ",
      if(sc %in% c("SC4", "SC5")) "cohort_profile <- cohort_profile |>
        select(ID_t, wave, tx8600y, tx8600m, tx80220) |> ",
      if(sc == "SC3") "cohort_profile <- cohort_profile |>
        select(ID_t, wave, tx8601y, tx8601m, tx80220) |>
        rename(tx8600m = tx8601m, tx8600y = tx8601y) |> ",
      "replace_values_with_na() |>",
      "mutate(month = ((tx8600y - 1960) * 12) + tx8600m - 1)  |>",
      "filter(tx80220 == 1 & !is.na(month)) |>",
      "select(-tx8600y, -tx8600m, -tx80220)",
      "",
      "bio <- left_join(cohort_profile, bio, by=c('ID_t','month'))",
      "rm(cohort_profile)",
      "",
      "# drop unnecessary vars",
      "bio <- bio |> ",
      "select(-starts_with('intd'), -worktime, -month, -splast)",
      "",
      if(length(datalist)>0) generate_strings(datalist, suf_version, english),
      if(length(datalist)>0) "",
      if(education) gen_qualification_prep_code_r(english, sc, suf_version, suf_version_short),
      if(education) "",
      if(further_training) further_training_gen_r(english,suf_version_short),
      if(further_training) "",
      if(children == T & sc %in% c("SC5", "SC6")) gen_children_example_r_sc5_6(english, sc, suf_version),
      if(children == T & sc %in% c("SC3", "SC4")) gen_children_example_r_sc3_4(english, sc, suf_version),
      if(children) "",
      if(set_missings) "# Additional Settings------------------------------------",
      if(set_missings)"",
      if(set_missings) "# set missings for all vars",
      if(set_missings)"bio <- replace_values_with_na(bio)"

    )
  }

  if(dataformat== "R" & subformat == "Original Subspell Format"){
    scripts <- c(
      "# R Script to generate a dataset in person year format. Harmonized spells from biography are being ignored - instead the original spell files are taken",
      "",
      "# This is a basic data preparation R script which only serves the purpose of demonstrating how one might generate a dataset in person-year-format by taking the subspells and not the harmonized spells from biography dataset as a baseline. Please carefully check each line and edit the script according to the needs of your research project",
      "",
      "#  - It is recommended to run this script line by line and make sence of it. ",
      "#  - List key variables over subspells, pay attention to missings in subspells",
      "#  - Eventually deal with missings by filling these with valid values from other subspells. Routines for that are partially provided in the script.",
      "",
      "rm(list = ls())",
      "",
      "# Load necessary libraries",
      "list.of.packages <- c('dplyr','haven','lubridate','tidyr','dtplyr')",
      "new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])] # check if required packages are in installed packages on this machine",
      "if(length(new.packages)) install.packages (new.packages) # if new.packages contains sth and thus length is > 0, install those new packages",
      "# load all required packages of the given package liste above",
      "invisible(lapply(list.of.packages, library, character.only = TRUE))",
      "",
      "",
      "# Set working directory and define file paths (adjust as needed)",
      paste0("datapath = ","'",datapath_conv,"/","'"),
      paste0("suf_version = ", "'", suf_version,"'"),
      paste0("suf_version_short = ", "'", suf_version_short,"'"),
      paste0("english = ", english),
      paste0("sc = ", "'",sc,"'"),
      "",
      "# Define variables",
      "standard_spell_vars <- c('ID_t', 'splink', 'subspell', 'spell', 'spgen', 'spext', 'spstat', 'disagint', 'disagwave', 'wave', 'spms')",
      "",
      if(sc=="SC6")"keep_vars <- c('ts1111m', 'ts1111y', 'ts1112m', 'ts1112y', 'ts1112c','ts1311m', 'ts1311y', 'ts1312m', 'ts1312y', 'ts1312c','ts15201_v1', 'ts15201', 'ts1511m', 'ts1511y', 'ts1512m', 'ts1512y', 'ts1512c','ts2111m', 'ts2111y', 'ts2112m', 'ts2112y', 'ts2112c','ts23223_g1', 'ts2311m', 'ts2311y', 'ts2312m', 'ts2312y', 'ts2312c','ts2511m', 'ts2511y', 'ts2512m', 'ts2512y', 'ts2512c','ts2711m', 'ts2711y', 'ts2712m', 'ts2712y', 'ts2712c','ts2911m', 'ts2911y', 'ts2912m', 'ts2912y', 'ts2912c', 'sptype')",
      if(sc %in% c("SC3", "SC4")) "keep_vars <- c('ts1111m', 'ts1111y', 'ts1112m', 'ts1112y', 'tf1112c','ts1311m', 'ts1311y', 'ts1312m', 'ts1312y', 'ts1312c', 'ts15201', 'ts1511m', 'ts1511y', 'ts1512m', 'ts1512y', 'ts1512c','ts2111m', 'ts2111y', 'ts2112m', 'ts2112y', 'ts2112c', 'ts23223', 'ts2311m', 'ts2311y', 'ts2312m', 'ts2312y', 'ts2312c','ts2511m', 'ts2511y', 'ts2512m', 'ts2512y', 'ts2512c','ts2711m', 'ts2711y', 'ts2712m', 'ts2712y', 'ts2712c','ts2911m', 'ts2911y', 'ts2912m', 'ts2912y', 'ts2912c', 'sptype')",
      if(sc == "SC5") "keep_vars <- c('ts1111m', 'ts1111y', 'ts1112m', 'ts1112y', 'ts1112c','ts1311m', 'ts1311y', 'ts1312m', 'ts1312y', 'ts1312c', 'ts15201', 'ts1511m', 'ts1511y', 'ts1512m', 'ts1512y', 'ts1512c','ts2111m', 'ts2111y', 'ts2112m', 'ts2112y', 'ts2112c', 'ts23223', 'ts2311m', 'ts2311y', 'ts2312m', 'ts2312y', 'ts2312c','ts2511m', 'ts2511y', 'ts2512m', 'ts2512y', 'ts2512c','ts2711m', 'ts2711y', 'ts2712m', 'ts2712y', 'ts2712c','ts2911m', 'ts2911y', 'ts2912m', 'ts2912y', 'ts2912c', 'sptype')",
      if(sc=='SC6')"fill_vars <- c('ts23223_g1', 'vt_typ')",
      if(sc %in% c("SC3", "SC4","SC5"))"fill_vars <- c('ts23223', 'vt_typ')",
      "# Load datasets",
      "school <- read_neps(paste0(datapath, '/', sc, '_spSchool_D_', suf_version, '.dta'), english = english) |>",
      "  mutate(sptype = 22)",
      "",
      "vocprep <- read_neps(paste0(datapath, '/', sc, '_spVocPrep_D_', suf_version, '.dta'), english = english) |>",
      "  mutate(sptype = 23)",
      "",
      "voctrain <- read_neps(paste0(datapath, '/', sc,'_spVocTrain_D_', suf_version, '.dta'), english = english) |>",
      "  mutate(sptype = 24)",
      "",
      "military <- read_neps(paste0(datapath, '/', sc,'_spMilitary_D_', suf_version, '.dta'), english = english) |>",
      "  mutate(sptype = 25)",
      "",
      "emp <- read_neps(paste0(datapath, '/', sc, '_spEmp_D_', suf_version, '.dta'), english = english) |>",
      "  mutate(sptype = 26)",
      "",
      "unemp <- read_neps(paste0(datapath, '/', sc, '_spUnemp_D_', suf_version, '.dta'), english = english) |>",
      "  mutate(sptype = 27)",
      "",
      "parleave <- read_neps(paste0(datapath, '/', sc, '_spParLeave_D_', suf_version, '.dta'), english = english) |>",
      "  mutate(sptype = 29)",
      "",
      "gap <- read_neps(paste0(datapath, '/', sc, '_spGap_D_', suf_version, '.dta'), english = english) |>",
      "  mutate(sptype = 30)",
      "",
      "# Combine all datasets into one",
      "bio <- bind_rows(",
      "  school, vocprep, voctrain, ",
      "  military, emp, unemp, ",
      "  parleave, gap",
      ")",
      "",
      "# after binding rows of numerical variables they lose their attracted variable labels, so we reassign them",
      if(english)"attr(bio$ID_t, 'label') <- 'ID target '",
      if(english)"attr(bio$splink, 'label') <- 'Link for spell merging'",
      if(english)"attr(bio$subspell, 'label') <- 'Number of subspell'",
      if(english)"attr(bio$spell, 'label') <- 'Spell number'",
      if(english)"attr(bio$sptype, 'label') <- 'Spell type'",
      if(!english)"attr(bio$ID_t, 'label') <- 'Target-ID '",
      if(!english)"attr(bio$splink, 'label') <- 'Link fÃ¼r Spell-Merging'",
      if(!english)"attr(bio$subspell, 'label') <- 'Teilepisodennummer'",
      if(!english)"attr(bio$spell, 'label') <- 'Spell Nummer'",
      if(!english)"attr(bio$sptype, 'label') <- 'Spell Typ'",
      "",
      "# remove single spell data files",
      "rm(school, vocprep, voctrain, ",
      "   military, emp, unemp, ",
      "   parleave, gap)",
      "",
      "# Assign labels to sptype",
      "bio$sptype <- factor(bio$sptype, ",
      "                                  levels = c(22, 23, 24, 25, 26, 27, 29, 30),",
      "                                  labels = c('school', 'vocprep', 'voctrain', 'military','employment', 'unemp', 'parleave', 'gap'))",
      "",
      "# Keep only specified variables",
      "bio <- bio  |> ",
      "  select(all_of(standard_spell_vars), all_of(keep_vars))",
      "",
      if(sc=="SC6")"# recode type of voc. training (different variable in Wave 1: ts15201_v1), and reduce to harmonized episodes (subspell==0)",
      if(sc=="SC6")"suppressWarnings({ # warnings are suppressed here because case_match throws a warning due to conflicting variable labels in ts15201 and ts15201_v1. This doesnt matter, because in the new variable 'vt_typ' the variable labels from ts15201 are being used and that is preferable in most cases. Change this if neccessary.",
      if(sc=="SC6")"  bio <- bio |>",
      if(sc=="SC6")"    mutate(",
      if(sc=="SC6")"      ts15201_v1 = case_match(",
      if(sc=="SC6")"        ts15201_v1,",
      if(sc=="SC6")"        # here the codes from the old voctrain-type var from wave 1 (ts15201_v1) are aligned with the new voctrain-type var ts15201 from wave 2+",
      if(sc=="SC6")"        2 ~ 3,",
      if(sc=="SC6")"        3 ~ 4,",
      if(sc=="SC6")"        4 ~ 5,",
      if(sc=="SC6")"        5 ~ 6,",
      if(sc=="SC6")"        6 ~ 9,",
      if(sc=="SC6")"        7 ~ 10,",
      if(sc=="SC6")"        8 ~ 15,",
      if(sc=="SC6")"        9 ~ 16,",
      if(sc=="SC6")"        10 ~ 11,",
      if(sc=="SC6")"        11 ~ 12,",
      if(sc=="SC6")"        12 ~ 13,",
      if(sc=="SC6")"        13 ~ 14,",
      if(sc=="SC6")"        14 ~ 17,",
      if(sc=="SC6")"        .default = ts15201_v1",
      if(sc=="SC6")"      ),",
      if(sc=="SC6")"      # Keep original value if not matched",
      if(sc=="SC6")"      # Replace `ts15201` with recoded `ts15201_v1` where `ts15201` is -54 (wave 1)",
      if(sc=="SC6")"      vt_typ = if_else(ts15201_v1 == -54, ts15201, ts15201_v1)",
      if(sc=="SC6")"    ) |> #gen new var 'vt_typ' with values from both orginal vars",
      if(sc=="SC6")"    select(-ts15201, -ts15201_v1)",
      if(sc=="SC6")"})",
      if(sc=="SC6")"",
      if(sc %in% c("SC3","SC4","SC5"))"  bio <- bio |>",
      if(sc %in% c("SC3","SC4","SC5"))"    mutate(vt_typ = ts15201) |>",
      if(sc %in% c("SC3","SC4","SC5"))"    select(-ts15201)",
      if(sc %in% c("SC3","SC4","SC5"))"",
      "# Recode working hours",
      if(sc=="SC6")"bio$ts23223_g1[bio$ts23223_g1 == -20] <- 90",
      if(sc=="SC6")"bio$ts23223_g1[bio$ts23223_g1 == -21] <- NA",
      if(sc %in% c("SC3","SC4","SC5"))"bio$ts23223[bio$ts23223 == -20] <- 90",
      if(sc %in% c("SC3","SC4","SC5"))"bio$ts23223[bio$ts23223 == -21] <- NA",
      "",
      "# Drop harmonized spells",
      "bio <- bio  |>  filter(!spstat %in% c(30, 31))",
      "",
      "# Fill missing values in specified variables 'fill_vars'",
      "bio <- bio |>",
      "  dtplyr::lazy_dt() |> # use this function from dtplyr for faster processing",
      "  group_by(ID_t, splink)  |> ",
      "  arrange(ID_t, splink, subspell)  |> ",
      "  tidyr::fill(all_of(fill_vars), .direction = 'down')  |> ",
      "  ungroup() |>",
      "  as_tibble()",
      "",
      "# Handle missing values (-98 and -97)",
      "all_date_vars <- c('ts2911m','ts2311m','ts2111m','ts2711m','ts1511m','ts1111m','ts1311m','ts2511m','ts2312m','ts2912m','ts2112m','ts2712m','ts1512m','ts1112m','ts1312m','ts2512m','ts2911y','ts2311y','ts2111y','ts2711y','ts1511y','ts1111y','ts1311y','ts2511y','ts2312y','ts2912y','ts2112y','ts2712y','ts1512y','ts1112y','ts1312y','ts2512y')",
      "bio <- replace_values_with_na(bio, vars=all_date_vars, values_to_replace=c(-97,-98))",
      "",
      "# Recode season codes in date variables",
      "bio <- replace_season_codes(bio, vars = c('ts2911m','ts2311m','ts2111m','ts2711m','ts1511m','ts1111m','ts1311m','ts2511m','ts2312m','ts2912m','ts2112m','ts2712m','ts1512m','ts1112m','ts1312m','ts2512m'))",
      "",
      "# Create start and end variables in terms of months since reference year 1960",
      "bio <- bio  |> ",
      "  # Create 'start' and 'end' as months since 1960, ensuring NA handling with coalesce",
      "  mutate(",
      "    start = ((ts2311y - 1960) * 12) + ts2311m - 1,",
      "    start = coalesce(start, ((ts2911y - 1960) * 12) + ts2911m - 1),",
      "    start = coalesce(start, ((ts2111y - 1960) * 12) + ts2111m - 1),",
      "    start = coalesce(start, ((ts2711y - 1960) * 12) + ts2711m - 1),",
      "    start = coalesce(start, ((ts1511y - 1960) * 12) + ts1511m - 1),",
      "    start = coalesce(start, ((ts1111y - 1960) * 12) + ts1111m - 1),",
      "    start = coalesce(start, ((ts1311y - 1960) * 12) + ts1311m - 1),",
      "    start = coalesce(start, ((ts2511y - 1960) * 12) + ts2511m - 1),",
      "    end = ((ts2312y - 1960) * 12) + ts2312m - 1,",
      "    end = coalesce(end, ((ts2912y - 1960) * 12) + ts2912m - 1),",
      "    end = coalesce(end, ((ts2112y - 1960) * 12) + ts2112m - 1),",
      "    end = coalesce(end, ((ts2712y - 1960) * 12) + ts2712m - 1),",
      "    end = coalesce(end, ((ts1512y - 1960) * 12) + ts1512m - 1),",
      "    end = coalesce(end, ((ts1112y - 1960) * 12) + ts1112m - 1),",
      "    end = coalesce(end, ((ts1312y - 1960) * 12) + ts1312m - 1),",
      "    end = coalesce(end, ((ts2512y - 1960) * 12) + ts2512m - 1)",
      "  ) |>",
      "  # Filter out rows where start or end are NA",
      "  filter(!is.na(start) & !is.na(end))  |> ",
      "  # Calculate duration in months",
      "  mutate(dur = end - start + 1)  |> ",
      "  # Select and remove original date columns",
      "  select(-c(ts2911m,ts2311m,ts2111m,ts2711m,ts1511m,ts1111m,ts1311m,ts2511m,ts2312m,ts2912m,ts2112m,ts2712m,ts1512m,ts1112m,ts1312m,ts2512m,",
      "            ts2911y,ts2311y,ts2111y,ts2711y,ts1511y,ts1111y,ts1311y,ts2511y,ts2312y,ts2912y,ts2112y,ts2712y,ts1512y,ts1112y,ts1312y,ts2512y)) # Remove original date columns",
      "",
      "# Assign varlabels to variables",
      if(english)"attr(bio$start, 'label') <- 'Start date'",
      if(english)"attr(bio$end, 'label') <- 'End date'",
      if(english)"attr(bio$dur, 'label') <- 'Duration'",
      if(!english)"attr(bio$start, 'label') <- 'Startdatum'",
      if(!english)"attr(bio$end, 'label') <- 'Enddatum'",
      if(!english)"attr(bio$dur, 'label') <- 'Dauer'",
      "",
      "# Keep only spells on the interview date",
      "bio <- bio |> ",
      if(sc %in% c("SC5","SC6"))"  filter(ts2312c == 1 | ts2912c == 1 | ts2112c == 1 | ts2712c == 1 | ts1512c == 1 | ts1112c == 1 | ts1312c == 1 | ts2512c == 1)",
      if(sc %in% c("SC3","SC4"))"  filter(ts2312c == 1 | ts2912c == 1 | ts2112c == 1 | ts2712c == 1 | ts1512c == 1 | tf1112c == 1 | ts1312c == 1 | ts2512c == 1)",
      "",
      "# drop revoked episodes from check module 30X",
      "bio <- bio |> ",
      "  filter(spms != -20)",
      "",
      "# Sort spells for priorisation",
      "bio <- bio |>",
      "mutate(",
      "prio = ifelse(vt_typ %in% 13:14, 31, sptype),",
      "prio = case_when(",
      paste("prio == ",prio_var[1]," ~ 1,"),
      paste("prio == ",prio_var[2]," ~ 2,"),
      paste("prio == ",prio_var[3]," ~ 3,"),
      paste("prio == ",prio_var[4]," ~ 4,"),
      paste("prio == ",prio_var[5]," ~ 5,"),
      paste("prio == ",prio_var[6]," ~ 6,"),
      paste("prio == ",prio_var[7]," ~ 7,"),
      paste("prio == ",prio_var[8]," ~ 8,"),
      paste("prio == ",prio_var[9]," ~ 9,"),
      paste("prio == ",prio_var[10]," ~ 10,"),
      "TRUE ~ NA_real_  # For values not specified, set to NA",
      "),",
      "    spms = tidyr::replace_na(spms, 0),",
      if(sc =="SC6")"    worktime = tidyr::replace_na(ts23223_g1, 0)",
      if(sc %in% c("SC3","SC4","SC5"))"    worktime = tidyr::replace_na(ts23223, 0)",
      "  )  |> ",
      "  arrange(ID_t, wave, prio, desc(spms), desc(worktime), desc(dur), splink)",
      if(parallel) "",
      if(parallel) gen_parallel_spells_r(format = "subspell"),
      "",
      # Prioritize: Within each combination of ID_t and wave, keep only the first row according to the specified sorting order
      "bio <- bio |> ",
      "  lazy_dt() |> # use this function from dtplyr for faster processing",
      "  group_by(ID_t, wave) |>",
      "  filter(row_number() == 1) |>",
      "  ungroup() |> ",
      "  as_tibble()",
      "",
      "# Check for unique waves",
      "if (any(duplicated(bio[c('ID_t', 'wave')]))) {",
      "  stop('Duplicated waves found.')",
      "}",
      "",
      "# Drop unnecessary variables",
      "bio <- bio  |> ",
      "  select(-starts_with('ts'), -prio, -spms, -starts_with('ts15201'))",
      "",
      if(length(datalist)>0) generate_strings(datalist,suf_version, english),
      if(length(datalist)>0) "",
      if(education) gen_qualification_prep_code_r(english, sc, suf_version,suf_version_short),
      if(education) "",
      if(further_training) further_training_gen_r(english, suf_version_short),
      if(further_training) "",
      if(children == T & sc %in% c("SC5", "SC6")) gen_children_example_r_sc5_6(english, sc, suf_version),
      if(children == T & sc %in% c("SC3", "SC4")) gen_children_example_r_sc3_4(english, sc, suf_version),
      if(children) "",
      if(set_missings) "# Additional Settings------------------",
      if(set_missings)"",
      if(set_missings) "# set missings for all vars",
      if(set_missings)"bio <- replace_values_with_na(bio)"
    )

  }
  if(dataformat == "STATA" & subformat == "Harmonized Spell Format (Recommended)") {
    scripts <- c(
      paste0(
        "* Base Dofile to transform NEPS ", sc, " SUF data into a person-year format"),
      "* It uses the harmonized spells (subspell==0) from the biography data as a base for this transformation process.",
      "* If you want acess to within spell variation across waves, spell related longitudinal information should be merged via 'ID_t', 'wave' and 'splink' after step 7, when the person-year structure has been generated and after dropping harmonized episodes in the spellfiles via 'keep if spstat < 30'. When you use the 'Additional variables' function in the app, this process is used. It ensures that timevariant spell information is not being lost. However it requires a handling of various missing value codes due to filtering or data issues. Examples are provided when using the 'Additional variables' function",
      "",
      "* !!!ATTENTION!!!" ,
      "* This is a basic data preparation script which serves the purpose of demonstrating how one might generate a dataset in person-year-format by taking the harmonized spells from biography as a baseline and merge infos from other datasets. Edits to the script that fit to you research project are possibly necessary and recommended.",
      "",
      "* Approach:",
      "",
      "* 1. Step: Load Biography dataset as a base for the person-year-dataset and generate start-, enddate and duration variables",
      "",
      "* 2. Step: Load Employment dataset and merge it to biograhpy in order to get access to working hours variable. This variable will be used in step 6 for priorisation of episode types",
      "",
      "* 3. Step: Load Voctrain dataset and merge it to biograhpy in order to get access to type of vocational training variable. This variable will also be used in the priorisation process",
      "",
      "* 4. Step: Load Cohortprofile dataset and merge it to biograhpy in order to get access to the interview dates. These are necessary for converting data into a person-year format, as this format focuses on respondents' information at each interview date.",
      "",
      "* 5. Step: Expand the data to a monthly format by multiplying each row of each respondent with the spell length in month (dur variable). This serves as the basis for the prioritization process in the next step.",
      "",
      "* 6. Step: Priorisation process. Here, we sort the months of each respondent by determined spell order, main/side episode (descending), working hours (descending), employment duration (descending) and splink. You may edit this according to your research question(s).",
      "",
      "* 7. Step: Reduce rows in dataset to interview date months by loading cohort profile, generating month variable and then merge this dataset to biography data by ID_t and month and keep only matches and using data. This will lead to a dataset with 1 row per wave of each respondent (what we call: 'person-year-dataset')",
      "",
      "* Additional data preparation steps may vary based on the settings configured in the Transform Data tab of the SUF-Explorer",
      "",
      "********************************************************************************",
      "clear",
      "set more off",
      "",
      if(english)"*install nepstools ado in order to be able to switch language",
      if(english)"net install nepstools, from(http://nocrypt.neps-data.de/stata)",
      if(english)"",
      "* paths ",
      paste0("global DATA = ","\"",datapath_conv,"/","\""),
      paste0("global suf ", "\"",suf_version, "\""),
      paste0("global suf_short ", "\"",suf_version_short, "\""),
      "",
      "",

      "********************************************************************************",
      "* 1. base: biography file",
      "********************************************************************************",
      paste0("use \"$DATA\\", sc, "_Biography_D_$suf.dta\", clear"),
      "mvdecode _all, mv(-98 -97 -54 -55 = .)",
      "",
      "* date variables",
      "gen start=ym(starty, startm)",
      "gen end=ym(endy, endm)",
      "drop startm starty endm endy",
      "",
      "format start end %tm",
      "lab var start \"Startdatum in Monaten seit Jan 1960\"",
      "lab var end \"Enddatum in Monaten seit Jan 1960\"",
      "",
      "drop if start == . | end == .",
      "",
      "* duration",
      "gen dur = end-start+1",
      "sum dur, detail // no negative values",
      "label var dur \"Dauer des Spells\"",
      "",
      "isid ID_t splink",
      "",
      "preserve",
      "",
      "********************************************************************************",
      "* 2. employment info",
      "********************************************************************************",
      paste0("use \"$DATA\\", sc, "_spEmp_D_$suf.dta\", clear"),
      if(sc == "SC6") "keep ID_t splink spell subspell ts23223_g1 ",
      if(sc == "SC6") "rename ts23223_g1 ts23223" else "keep ID_t splink spell subspell ts23223",
      "",
      "recode ts23223 (-20 = 90) (-21 = .)",
      "",
      "* keep only harmonized spells - necessary in order to merge it to biography via ID_t and splink",
      "keep if subspell == 0",
      "",
      "tempfile emp",
      "save `emp'",
      "",
      "restore",
      "",
      "merge 1:1 ID_t splink using `emp', keep(1 3) nogen",
      "",
      "preserve",
      "",
      "********************************************************************************",
      "* 3. voc train info for priorization",
      "********************************************************************************",
      paste0("use \"$DATA\\", sc, "_spVocTrain_D_$suf.dta\", clear"),
      if(sc=="SC6") "keep ID_t splink subspell ts15201_v1 ts15201" else "keep ID_t splink subspell ts15201",
      "",
      if(sc=="SC6")"* harmonize type of voctraining",
      if(sc=="SC6")"* first we need to align the codes of both variables because they differ unfortunately",
      if(sc=="SC6")"clonevar vt_typ_v1 = ts15201_v1",
      if(sc=="SC6")"recode vt_typ_v1 (2=3) (3=4) (4=5) (5=6) (6=9) (7=10) (8=15) (9=16) (10=11) (11=12) (12=13) (13=14) (14=17)",
      if(sc=="SC6")"label define de1876 15 \"Promotion\" 16 \"Habilitation\" 17 \"eine andere Ausbildung\", modify",
      if(sc=="SC6")"clonevar vt_typ = ts15201",
      if(sc=="SC6")"replace vt_typ = vt_typ_v1 if vt_typ == -54 ",
      "",
      if(sc %in% c("SC3","SC4","SC5"))"rename ts15201 vt_typ",
      "",
      "* keep only harmonized spells",
      "keep if subspell == 0 ",
      "",
      if(sc=="SC6")"drop ts15201_v1 ts15201 vt_typ_v1",
      "tempfile vt",
      "save `vt'",
      "",
      "restore",
      "merge 1:1 ID_t splink using `vt', keep(1 3) nogen",
      "",
      "********************************************************************************",
      "* 4. merge interview dates",
      "*******************************************************************************",
      "preserve",
      "",
      paste0("use \"$DATA\\", sc, "_CohortProfile_D_$suf.dta\", clear"),
      "",
      if(sc %in% c("SC3","SC6"))"keep ID_t wave tx8601y tx8601m",
      if(sc %in% c("SC4","SC5"))"keep ID_t wave tx8600y tx8600m",
      "",
      "* gen interviewdate",
      if(sc %in% c("SC3","SC6"))"gen intd = ym(tx8601y,tx8601m)",
      if(sc %in% c("SC4","SC5"))"gen intd = ym(tx8600y,tx8600m)",
      "format intd %tm",
      "",
      if(sc %in% c("SC3","SC6"))"drop tx8601y tx8601m",
      if(sc %in% c("SC4","SC5"))"drop tx8600y tx8600m",
      "",
      "bys ID_t (wave): gen firstwave = wave[1]",
      "label var firstwave \"Startwelle\"",
      "",
      "* reshape interview dates to wideform format",
      "reshape wide intd, i(ID_t) j(wave)",
      "",
      "tempfile intd",
      "save `intd'",
      "",
      "restore",
      "",
      "merge m:1 ID_t using `intd', keep(match) nogen",
      "",
      "********************************************************************************",
      "* 5. expand dataframe to 'months-structure'",
      "********************************************************************************",
      "",
      "* expands the dataset by variable dur -> generates rows corresponding to the value in dur",
      "expand dur",
      "",
      "sort ID_t splink",
      "",
      "bys ID_t splink: gen n = _n -1",
      "",
      "gen month = start + n",
      "format month %tm",
      "",
      "drop n",
      "",
      "********************************************************************************",
      "* 6. priorisation",
      "********************************************************************************",
      "",
      "* to prioritize multiple parallel employment spells, we consider multiple variables in the following order of relevance: priolist, spms (main vs side episode), working hours, employment duration and splink",
      "* sort parallel Episodes",
      "clonevar prio = sptype",
      "",
      "* recode licences courses and ihk courses to value 31 to place it behind xmodule episodes in the priorisation order because these types of episodes are considered of minor importance in many research projects in regard to spell priorisation.",
      "recode prio 24= 31 if inrange(vt_typ,13,14)",
      "",
      paste0("recode prio ","(",prio_var[1],  " = 1)"," (",prio_var[2]," = 2)"," (",prio_var[3]," = 3)"," (",prio_var[4]," = 4)"," (",prio_var[5]," = 5)"," (",prio_var[6]," = 6)"," (",prio_var[7]," = 7)"," (",prio_var[8]," = 8)"," (",prio_var[9]," = 9)"," (",prio_var[10]," = 10)",",gen(prio_temp)"),
      "* for sorting set side episodes und missings to 0",
      "recode spms (1 = 1) (2 . = 0)",
      "",
      "clonevar worktime = ts23223",
      "replace worktime = 0 if missing(ts23223) //recode missings to 0 for sorting",
      "",
      "gsort ID_t month prio -spms -worktime -dur splink // this is the overall priorisation order",
      "",
      if(parallel) gen_parallel_spells_stata(format="harmonized"),
      "* Now, we prioritize by reducing to the first month within each individual that holds the prioritized spell",
      "by ID_t month: keep if _n == 1",
      "drop worktime prio prio_temp wave ts23223 vt_typ intd*",
      "",
      "********************************************************************************",
      "* 7. create person year format",
      "********************************************************************************",
      "",
      "* load interview dates from cohortprofile and merge it to the biography by ID_t and month. This will keep only rows (months) that correspond to actual interview dates from cohort profile. Finally this leads to a format with 1 row per year of a person where information is centered around each interview date",
      "preserve",
      paste0("use \"$DATA\\", sc, "_CohortProfile_D_$suf.dta\", clear"),
      "",
      if(sc %in% c("SC3", "SC6"))"keep ID_t wave tx8601y tx8601m tx80220",
      if(sc %in% c("SC4", "SC5"))"keep ID_t wave tx8600y tx8600m tx80220",
      "",
      "* gen interview month",
      if(sc %in% c("SC3", "SC6"))"gen month = ym(tx8601y,tx8601m)",
      if(sc %in% c("SC4", "SC5"))"gen month = ym(tx8600y,tx8600m)",
      "format month %tm",
      "",
      "* drop non-participants",
      "drop if tx80220 != 1 | missing(month)",
      "",
      if(sc == "SC5") "*drop wave duplicates in order to be able to merge it to the biography data from before",
      if(sc == "SC5") "bys ID_t month: gen n = _n",
      if(sc == "SC5") "drop if n > 1",
      if(sc == "SC5") "drop n",
      if(sc == "SC5") "",
      if(sc %in% c("SC3", "SC6"))"drop tx8601y tx8601m tx80220",
      if(sc %in% c("SC4", "SC5"))"drop tx8600y tx8600m tx80220",
      "",
      "tempfile intd",
      "save `intd'",
      "",
      "restore",
      "",
      "merge 1:1 ID_t month using `intd', nogen keep(match)",
      "",
      if(length(datalist)>0) generate_strings_stata(datalist, suf_version),
      if(length(datalist)>0) "",
      if(education) gen_qualification_prep_code_stata(english, sc,suf_version,suf_version_short),
      if(education) "",
      if(further_training)"",
      if(further_training) further_training_gen_stata(english, suf_version_short),
      if(further_training) "",
      if(children == T & sc %in% c("SC5", "SC6")) gen_children_example_stata_sc5_6(english, sc, suf_version),
      if(children == T & sc %in% c("SC3", "SC4")) gen_children_example_stata_sc3_4(english, sc, suf_version),
      if(children)"",
      if(set_missings | english)"********************************************************************************",
      if(set_missings | english) "* Additional Settings",
      if(set_missings | english)"********************************************************************************",
      if(set_missings)"",
      if(set_missings)"* set missings for all variables",
      if(set_missings)"mvdecode _all, mv(-98 = .a \\ -97 = .b \\ -54 = .c \\ -55 = .d ) // alternatively one can use the 'nepsmiss' function from nepstools ado",
      if(set_missings)"",
      if(english)"*switch variable and value labels to english",
      if(english)"label language en",
      if(english)"",
      if(english)"* label generated variables with english labels",
      if(english)"label var start \"Date of episode start\"",
      if(english)"label var end \"Date of episode end\"",
      if(english)"label var dur \"Duration of episode\"",
      if(english)"label var firstwave \"First wave\"",
      if(english)"label var month \"Month\""
    )
  }

  if(dataformat == "STATA" & subformat == "Original Subspell Format"){
    scripts <- c(
      "* Dofile for generating dataset in person year format. Harmonized spells from biography are being ignored - instead the original spell files are taken",
      "",
      "********************************************************************************",
      "  *** !!!ATTENTION!!! ",
      "  * This is a basic data preparation script which serves the purpose of demonstrating how one might generate a dataset in person-year-format by taking the subspells and not the harmonized spells from biography dataset as a baseline. Edits to the script that fit to you research project are possibly necessary and recommended.",
      "",
      "* - It is recommended to run this script line by line and make sence of it. ",
      "* - List key variables over subspells, pay attention to missings in subspells",
      "* - Eventually deal with missings by filling these with valid values from other subspells. Routines are provided in the script.",
      "********************************************************************************",
      "",
      "clear",
      "set more off",
      "",
      if(english==T)"*install nepstools ado in order to be able to switch language",
      if(english==T)"net install nepstools, from(http://nocrypt.neps-data.de/stata)",
      if(english==T)"",
      "* paths ",
      paste0("global DATA = ","\"",datapath_conv,"/","\""),
      paste0("global suf ", "\"",suf_version, "\""),
      paste0("global suf_short ", "\"",suf_version_short,"\""),
      "",
      "global standard_spell_vars ID_t splink subspell spell spgen spext spstat disagint disagwave wave spms sptype",
      if(sc == "SC6")"global keep_vars ts1111m ts1111y ts1112m ts1112y ts1112c ts1311m ts1311y ts1312m ts1312y ts1312c ts1511m ts1511y ts1512m ts1512y ts1512c ts2111m ts2111y ts2112m ts2112y ts2112c  ts2311m ts2311y ts2312m ts2312y ts2312c ts2511m ts2511y ts2512m ts2512y ts2512c  ts2711m ts2711y ts2712m ts2712y  ts2712c ts2911m ts2911y ts2912m ts2912y ts2912c ts23223_g1 ts15201_v1 ts15201",
      if(sc %in% c("SC3","SC4"))"global keep_vars ts1111m ts1111y ts1112m ts1112y tf1112c ts1311m ts1311y ts1312m ts1312y ts1312c ts1511m ts1511y ts1512m ts1512y ts1512c ts2111m ts2111y ts2112m ts2112y ts2112c  ts2311m ts2311y ts2312m ts2312y ts2312c ts2511m ts2511y ts2512m ts2512y ts2512c  ts2711m ts2711y ts2712m ts2712y  ts2712c ts2911m ts2911y ts2912m ts2912y ts2912c ts15201 ts23223",
      if(sc == "SC5")"global keep_vars ts1111m ts1111y ts1112m ts1112y ts1112c ts1311m ts1311y ts1312m ts1312y ts1312c ts1511m ts1511y ts1512m ts1512y ts1512c ts2111m ts2111y ts2112m ts2112y ts2112c  ts2311m ts2311y ts2312m ts2312y ts2312c ts2511m ts2511y ts2512m ts2512y ts2512c  ts2711m ts2711y ts2712m ts2712y  ts2712c ts2911m ts2911y ts2912m ts2912y ts2912c ts15201 ts23223",
      if(sc == "SC6")"global fill_vars ts23223_g1 vt_typ",
      if(sc %in% c("SC3","SC4","SC5"))"global fill_vars ts23223 vt_typ",
      "",
      "",
      "********************************************************************************",
      "  * 1. Append spelldata files",
      "********************************************************************************",
      "",
      paste0("use \"$DATA\\", sc, "_spSchool_D_$suf.dta\", clear"),
      "gen sptype = 22",
      "",
      paste0("append using \"$DATA\\", sc, "_spVocPrep_D_$suf.dta\""),
      "replace sptype = 23 if sptype == .",
      "",
      paste0("append using \"$DATA\\", sc, "_spVocTrain_D_$suf.dta\""),
      "replace sptype = 24 if sptype == .",
      "",
      paste0("append using \"$DATA\\", sc, "_spMilitary_D_$suf.dta\""),
      "replace sptype = 25 if sptype == .",
      "",
      paste0("append using \"$DATA\\", sc, "_spEmp_D_$suf.dta\""),
      "replace sptype = 26 if sptype ==.",
      "",
      paste0("append using \"$DATA\\", sc, "_spUnemp_D_$suf.dta\""),
      "replace sptype = 27 if sptype == .",
      "",
      paste0("append using \"$DATA\\", sc, "_spParLeave_D_$suf.dta\""),
      "replace sptype = 29 if sptype == .",
      "",
      paste0("append using \"$DATA\\", sc, "_spGap_D_$suf.dta\""),
      "replace sptype = 30 if sptype == .",
      "",
      "label var sptype \"spelltype\"",
      "label define sptype 22 \"school\" 23 \"vocprep\" 24 \"voctrain\" 25 \"military\" 26 \"employment\" 27 \"unemp\" 29 \"parleave\" 30 \"gap\"",
      "label val sptype sptype",
      "",
      "* keep only specified vars",
      "keep $standard_spell_vars $standard_spell_vars $keep_vars ",
      "",
      "*** data prep of indicators that are necessary for spell priorisation later ***",
      if(sc=="SC6")"* harmonize type of voctraining",
      if(sc=="SC6")"* first we need to align the codes of both variables because they differ unfortunately",
      if(sc=="SC6")"clonevar vt_typ_v1 = ts15201_v1",
      if(sc=="SC6")"recode vt_typ_v1 (2=3) (3=4) (4=5) (5=6) (6=9) (7=10) (8=15) (9=16) (10=11) (11=12) (12=13) (13=14) (14=17)",
      if(sc=="SC6")"label define de1876 15 \"Promotion\" 16 \"Habilitation\" 17 \"eine andere Ausbildung\", modify",
      if(sc=="SC6")"clonevar vt_typ = ts15201",
      if(sc=="SC6")"replace vt_typ = vt_typ_v1 if vt_typ == -54 ",
      if(sc=="SC6")"drop vt_typ_v1 ts15201 ts15201_v1",
      if(sc %in% c("SC3","SC4","SC5")) "rename ts15201 vt_typ",
      "",
      "* Working hours recoding",
      if(sc=="SC6")"recode ts23223_g1 (-20 = 90) (-21 = .)",
      if(sc %in% c("SC3","SC4","SC5"))"recode ts23223 (-20 = 90) (-21 = .)",
      "* drop harmonized spells",
      "drop if inlist(spstat,30,31)",
      "",
      "* Not all variables have consistent info over the subspells, so we might fill missings with values from subspells before. Edit this if you prefer a different approach. Examples are provided and commented out. Combinations are possible, e.g. 1 and 2. - not all combinations make sence, e.g. 1. and 3.",
      "* One might use different approaches for different variables --> in this case multiple loops are required.",
      "* Set Missings on variables used for priorisation later. It is recommended to use the function nepsmiss from the nepstools ado to recode all missing values to specific missing codes. You may install it with: net install nepstools, from(http://nocrypt.neps-data.de/stata). If you want to exclude specific missings from being recoded you might use statas mvdecode function instead.",
      "nepsmiss _all",
      "",
      "foreach var of varlist $fill_vars  {",
      "  bys ID_t splink (subspell): replace `var' = `var'[_n-1] if missing(`var') & !missing(`var'[_n-1]) //fill missings from preceding rows",
      "* bys ID_t splink (subspell): replace `var' = `var'[_n+1] if missing(`var') & !missing(`var'[_n+1]) //fill missings from subsequent rows",
      "* bys ID_t splink (subspell): replace `var' = `var'[1] if missing(`var') & !missing(`var'[1]) //fill missings from with value from first row",
      "* gsort ID_t splink -subspell // this belongs the the subsequent row, we order subspells in descending order to easily access the last value of group ID_t and splink",
      "* by ID_t splink : replace `var' = `var'[1] if missing(`var') & !missing(`var'[1]) //fill missings with value from last row",
      "* sort ID_t splink subspell // sort in natural way again",
      "}",
      "",
      "* generate date variable from actual respondent information (_g date variables have problems)",
      "mvdecode ts2311m ts2312m ts2312y ts2911m ts2911y ts2912m ts2912y ts2111m ts2111y ts2112m ts2112y ts2711m ts2711y ts2712m ts2712y  ts1511m ts1511y ts1512m ts1512y  ts1111m ts1111y ts1112m ts1112y  ts1311m ts1311y ts1312m ts1312y  ts2511m ts2511y ts2512m ts2512y , mv(-98 -97)",
      "",
      "* recode season codes in date variables",
      "foreach var of varlist ts2311m ts2312m ts2312y  ts2911m ts2911y ts2912m ts2912y  ts2111m ts2111y ts2112m ts2112y  ts2711m ts2711y ts2712m ts2712y  ts1511m ts1511y ts1512m ts1512y  ts1111m ts1111y ts1112m ts1112y  ts1311m ts1311y ts1312m ts1312y  ts2511m ts2511y ts2512m ts2512y {",
      "	recode `var' (21=1) (24=4) (27 = 7 ) (30=10) (32 = 12)",
      "}",
      "",
      "* gen startdate variable",
      "gen start=ym(ts2311y, ts2311m) // Emp",
      "replace start = ym(ts2911y, ts2911m) if start == . // Gap",
      "replace start = ym(ts2111y, ts2111m) if start == . // Military",
      "replace start = ym(ts2711y, ts2711m) if start == . // ParLeave",
      "replace start = ym(ts1511y, ts1511m) if start == . // VocTrain",
      "replace start = ym(ts1111y, ts1111m) if start == . // School",
      "replace start = ym(ts1311y, ts1311m) if start == . // VocPrep",
      "replace start = ym(ts2511y, ts2511m) if start == . // Unemp",
      "",
      "* gen enddate variable",
      "gen end=ym(ts2312y, ts2312m) // Emp",
      "replace end = ym(ts2912y, ts2912m) if end == . // Gap",
      "replace end = ym(ts2112y, ts2112m) if end == . // Military",
      "replace end = ym(ts2712y, ts2712m) if end == . // ParLeave",
      "replace end = ym(ts1512y, ts1512m) if end == . // VocTrain",
      "replace end = ym(ts1112y, ts1112m) if end == . // School",
      "replace end = ym(ts1312y, ts1312m) if end == . // VocPrep",
      "replace end = ym(ts2512y, ts2512m) if end == . // Unemp",
      "",
      "* format this var",
      "format start %tm",
      "format end %tm ",
      "",
      "* drop spells with missing dates ",
      "drop if start == . | end == .",
      "",
      "* duration",
      "gen dur = end-start+1",
      "sum dur, detail // no negative values",
      "",
      "* keep only lasting spells on interview date",
      "gen keep = .",
      if(sc %in% c("SC3","SC4")) "foreach var of varlist ts2312c ts2912c ts2112c ts2712c ts1512c tf1112c ts1312c ts2512c {",
      if(sc %in% c("SC6","SC5")) "foreach var of varlist ts2312c ts2912c ts2112c ts2712c ts1512c ts1112c ts1312c ts2512c {",
      "  replace keep = 1 if `var' == 1",
      "}",
      "keep if keep == 1",
      "drop keep",
      "",
      "* drop revoked episodes from check module 30X",
      "drop if spms == -20",
      "",
      "sort ID_t wave sptype",
      "",
      "**********************************************",
      "* 2. Spell Priorisation: reduce to 1 obs per row",
      "**********************************************",
      "",
      "* to prioritize multiple parallel employment spells, we consider multiple variables in the following order of relevance: priolist, spms (main vs side episode from biography), working hours, employment duration and splink",
      "* sort parallel Episodes",
      "clonevar prio = sptype",
      "",
      "* recode licences courses and ihk courses to value 31 to place it behind xmodule episodes in the priorisation order because these types of episodes are considered of minor importance in many research projects in regard to spell priorisation.",
      "recode prio 24= 31 if inrange(vt_typ,13,14)",
      "",
      paste0("recode prio ","(",prio_var[1],  " = 1)"," (",prio_var[2]," = 2)"," (",prio_var[3]," = 3)"," (",prio_var[4]," = 4)"," (",prio_var[5]," = 5)"," (",prio_var[6]," = 6)"," (",prio_var[7]," = 7)"," (",prio_var[8]," = 8)"," (",prio_var[9]," = 9)"," (",prio_var[10]," = 10)",",gen(prio_temp)"),
      "* for sorting set nebenbeschÃ¤ftigungen und missings to 0",
      "recode spms (1 = 1) (2 . = 0)",
      "",
      if(sc=="SC6")"clonevar worktime = ts23223_g1",
      if(sc=="SC6")"replace worktime = 0 if missing(ts23223_g1) //recode missings to 0 for gsorting",
      if(sc %in% c("SC3","SC4","SC5")) "clonevar worktime = ts23223",
      if(sc %in% c("SC3","SC4","SC5")) "replace worktime = 0 if missing(ts23223) //recode missings to 0 for gsorting",
      "",
      "* are these variables unique identifiers?",
      "",
      "* gsort them in the following order. This order is our priorisation rule in the following order of importance: ID_t, wave, spelltype, main or side spell, working hours, duration of episode, splink (order of spell collection)",
      "gsort ID_t wave prio -spms -worktime -dur splink",
      "",
      if(parallel) gen_parallel_spells_stata(format = "subspell"),
      "* reduce to the first month within each individual that holds the prioritized spell",
      "by ID_t wave: keep if _n == 1",
      "",
      "*check for unique waves",
      "isid ID_t wave",
      "",
      "*drop vars that are not required anymore",
      if(sc %in% c("SC3","SC4"))"drop ts1111m ts1111y ts1112m ts1112y tf1112c ts1311m ts1311y ts1312m ts1312y ts1312c ts1511m ts1511y ts1512m ts1512y ts1512c ts2111m ts2111y ts2112m ts2112y ts2112c ts2311m ts2311y ts2312m ts2312y ts2312c ts2511m ts2511y ts2512m ts2512y ts2512c ts2711m ts2711y ts2712m ts2712y ts2712c ts2911m ts2911y ts2912m ts2912y ts2912c prio worktime",
      if(sc %in% c("SC5","SC6"))"drop ts1111m ts1111y ts1112m ts1112y ts1112c ts1311m ts1311y ts1312m ts1312y ts1312c ts1511m ts1511y ts1512m ts1512y ts1512c ts2111m ts2111y ts2112m ts2112y ts2112c ts2311m ts2311y ts2312m ts2312y ts2312c ts2511m ts2511y ts2512m ts2512y ts2512c ts2711m ts2711y ts2712m ts2712y ts2712c ts2911m ts2911y ts2912m ts2912y ts2912c prio worktime",
      "",
      if(length(datalist)>0) generate_strings_stata(datalist, suf_version),
      if(length(datalist)>0)"",
      if(education) gen_qualification_prep_code_stata(english, sc, suf_version,suf_version_short),
      if(education) "",
      if(further_training)"",
      if(further_training) further_training_gen_stata(english, suf_version_short),
      if(further_training) "",
      if(children == T & sc %in% c("SC5", "SC6")) gen_children_example_stata_sc5_6(english, sc, suf_version),
      if(children == T & sc %in% c("SC3", "SC4")) gen_children_example_stata_sc3_4(english, sc, suf_version),
      if(children)"",
      if(set_missings | english)"********************************************************************************",
      if(set_missings | english) "* Additional Settings",
      if(set_missings | english)"********************************************************************************",
      if(set_missings)"",
      if(set_missings)"* set missings for all variables",
      if(set_missings)"mvdecode _all, mv(-98 = .a \\ -97 = .b \\ -54 = .c \\ -55 = .d ) // alternatively one can use the 'nepsmiss' function from nepstools ado",
      if(set_missings)"",
      if(english)"*switch variable and value labels to english",
      if(english)"label language en"
    )
  }
  return(scripts)
}
